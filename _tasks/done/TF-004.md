# TF-004: Cloud Run Terraform module

**Component:** Terraform
**Phase:** 3
**Depends on:** TF-001
**Estimated effort:** L

---

## Description

Create the Terraform module that provisions all GCP infrastructure required by the Cloud Run backend. This module is used by the `cloudrun-test` environment and any production Cloud Run deployments. The module enables required APIs, creates the networking stack (VPC, subnet, Serverless VPC Access connector), service discovery (Cloud DNS private zone), shared storage (GCS bucket), image registry (Artifact Registry), IAM service account with least-privilege roles, and logging configuration. Every resource the Cloud Run backend binary (GCR-001 through GCR-004) expects to exist at runtime is created by this module.

---

## Context

### Cloud Run backend infrastructure requirements

The Cloud Run backend (see GCR-001) requires these GCP resources to be pre-provisioned:

```yaml
cloudrun:
  project: my-gcp-project
  region: us-central1
  vpc_connector: "projects/my-project/locations/us-central1/connectors/sockerless"
  gcs_bucket: sockerless-volumes
  log_filter: ""
```

### Networking requirements (GCR-004)

- VPC network and subnet for the Serverless VPC Access connector
- Serverless VPC Access connector so Cloud Run Jobs can access VPC resources (Cloud DNS, other services)
- Cloud DNS private zone associated with the VPC for service discovery (container alias DNS resolution)
- Cloud Run Jobs with VPC connector can communicate with other resources on the same VPC

### Volume requirements (GCR-004)

- GCS bucket for volume mounts via Cloud Storage FUSE
- Cloud Run service account needs `roles/storage.objectAdmin` on the bucket
- Bucket path prefix `volumes/` for named volumes

### Container operations requirements (GCR-002)

- Cloud Run Jobs API enabled (`run.googleapis.com`)
- IAM service account for Cloud Run job executions
- Service account needs Cloud Run Invoker role to start executions

### Log requirements (GCR-003)

- Cloud Logging API enabled (`logging.googleapis.com`)
- Service account needs logging write permissions
- Optional: Cloud Logging sink for structured log routing to a dedicated destination

### Image operations requirements (GCR-003)

- Artifact Registry repository for storing the sockerless-agent image and loaded container images
- Artifact Registry API enabled (`artifactregistry.googleapis.com`)
- Service account needs Artifact Registry Reader and Writer roles

### Agent injection requirements (GCR-003)

- For the startup command agent injection method: GCS bucket with the agent binary, readable by the Cloud Run service account
- For the image layer method: Artifact Registry repository for wrapper images

---

## Acceptance Criteria

### API Enablement
1. The module enables required GCP APIs on the project: `run.googleapis.com` (Cloud Run), `vpcaccess.googleapis.com` (Serverless VPC Access), `dns.googleapis.com` (Cloud DNS), `logging.googleapis.com` (Cloud Logging), `artifactregistry.googleapis.com` (Artifact Registry), `storage.googleapis.com` (Cloud Storage).
2. API enablement uses `google_project_service` with `disable_on_destroy = false` to avoid disabling shared APIs when the module is destroyed.

### VPC and Networking
3. A VPC network is created (or an existing VPC ID is accepted via variable) with auto-create subnetworks disabled.
4. A subnet is created in the configured region with a configurable CIDR range (default `10.8.0.0/28` -- the minimum /28 required by VPC Access connectors).
5. A Serverless VPC Access connector is created in the configured region, attached to the subnet, with configurable machine type (default `e2-micro`) and min/max instance count (default `2`/`3`).
6. The VPC connector name is exported as an output for use in Cloud Run Job configuration.

### Cloud DNS
7. A Cloud DNS private managed zone is created with a configurable DNS name suffix (default `sockerless.internal.`).
8. The DNS zone is associated with the VPC network so Cloud Run Jobs using the VPC connector can resolve private DNS records.
9. The DNS zone name is exported as an output for use by the Cloud Run backend (GCR-004) when creating per-network DNS records.

### Cloud Storage
10. A GCS bucket is created with a configurable name (default `${project_name}-sockerless-volumes`), location matching the configured region, and uniform bucket-level access enabled.
11. The bucket has a configurable lifecycle rule to delete objects older than N days (default 30 days) to clean up stale volume data.
12. Versioning is disabled by default (volume data is transient) but configurable.
13. The bucket name is exported as an output for use in Cloud Run backend configuration.

### Artifact Registry
14. An Artifact Registry Docker repository is created in the configured region with a configurable repository name (default `sockerless`).
15. The repository is configured with cleanup policies to delete untagged images after a configurable period (default 7 days).
16. The repository URL is exported as an output (format: `REGION-docker.pkg.dev/PROJECT/REPO`).

### IAM
17. A GCP service account is created for Cloud Run job executions with a configurable name (default `sockerless-runner`).
18. The service account is granted least-privilege IAM roles on the project: `roles/run.invoker` (start job executions), `roles/logging.logWriter` (write logs), `roles/storage.objectAdmin` (read/write GCS bucket for volumes), `roles/dns.admin` (manage DNS records in the private zone), `roles/artifactregistry.reader` (pull images from Artifact Registry).
19. For the agent GCS bucket (if using startup command injection), the service account is granted `roles/storage.objectViewer` on the agent bucket.
20. IAM bindings are scoped to the specific resources where possible (bucket-level IAM for GCS, repository-level IAM for Artifact Registry) rather than project-level grants.
21. The service account email is exported as an output for use in Cloud Run Job configuration.

### Logging
22. A Cloud Logging log sink is optionally created (configurable, default disabled) to route Cloud Run job logs to a dedicated destination (GCS bucket or BigQuery dataset).
23. If the log sink is enabled, the destination resource is created and the sink's writer identity is granted appropriate permissions.

### Module Interface
24. All configurable parameters are exposed as variables with `description`, `type`, `default`, and `validation` blocks where appropriate.
25. Key outputs are exported: `project_id`, `region`, `vpc_network_name`, `vpc_network_id`, `subnet_name`, `vpc_connector_name`, `vpc_connector_id`, `dns_zone_name`, `dns_zone_dns_name`, `gcs_bucket_name`, `gcs_bucket_url`, `artifact_registry_repository_name`, `artifact_registry_repository_url`, `service_account_email`, `service_account_id`.
26. `terraform plan` produces no errors when run against the module with default variable values and a valid GCP project.
27. All resources are labeled with the standard Sockerless labels: `project`, `environment`, `component = "cloudrun"`, `managed-by = "terraform"` (using GCP's `labels` field where supported).

---

## Definition of Done

### Code Quality
- [ ] `terraform fmt -check` passes with zero formatting differences on all module files
- [ ] `terraform validate` passes with zero errors
- [ ] No deprecated resource types or attributes used
- [ ] HCL follows HashiCorp style conventions (2-space indent, sorted arguments)

### Testing
- [ ] `terraform init` and `terraform validate` succeed in the module directory
- [ ] `terraform plan` with default variable values produces no errors (requires GCP project)
- [ ] Variable validation blocks reject invalid inputs (e.g., invalid region, invalid CIDR)
- [ ] Module can be instantiated multiple times in the same GCP project with different names

### Documentation
- [ ] All variables have `description` fields
- [ ] All outputs have `description` fields
- [ ] Module header comment in `main.tf` describes purpose, usage, and prerequisites
- [ ] README section in `terraform/README.md` updated with Cloud Run module usage example

### Integration
- [ ] Output values match the configuration keys expected by the Cloud Run backend (GCR-001): `project`, `region`, `vpc_connector`, `gcs_bucket`
- [ ] VPC connector enables Cloud Run Jobs to access VPC resources (Cloud DNS, other services)
- [ ] Cloud DNS zone can be used by GCR-004 for service discovery
- [ ] GCS bucket accessible from Cloud Run Jobs via FUSE for volume mounts (GCR-004)
- [ ] Artifact Registry accessible for image pull/push operations (GCR-003)
- [ ] No breaking changes to the TF-001 scaffold structure

---

## Suggested File Paths

```
terraform/modules/cloudrun/
├── main.tf              # Project data source, API enablement
├── variables.tf         # All input variables with descriptions and defaults
├── outputs.tf           # All exported outputs with descriptions
├── versions.tf          # Terraform >= 1.5, Google provider ~> 5.0
├── vpc.tf               # VPC network, subnet, Serverless VPC Access connector
├── dns.tf               # Cloud DNS private managed zone
├── storage.tf           # GCS bucket for volumes, lifecycle rules
├── artifact_registry.tf # Docker repository, cleanup policies
├── iam.tf               # Service account, role bindings (project and resource level)
├── logging.tf           # Optional log sink and destination
└── locals.tf            # Merged labels, computed values
```

---

## Notes

- The GCP project must already exist. This module does not create GCP projects. The project ID is a required input variable. Use `google_project` data source to reference the existing project.
- Serverless VPC Access connector requires a `/28` subnet (minimum). The connector provisions 2-10 `e2-micro` instances to bridge Cloud Run to the VPC. For test environments, `e2-micro` with min 2 / max 3 instances is cost-effective (~$7/month). For production, consider larger instance types.
- Cloud DNS private zones are only resolvable from within the associated VPC. Cloud Run Jobs must use the VPC connector to resolve private DNS names. Without the VPC connector, DNS queries for the private zone will fail.
- GCS FUSE mounts in Cloud Run require the Cloud Storage API to be enabled and the service account to have appropriate storage permissions. FUSE mounts add latency (10-50ms per operation) compared to local filesystem access, but this is acceptable for CI workloads.
- Artifact Registry pricing: storage is $0.10/GB-month. Docker image layers are deduplicated, so storing multiple tags of the same image consumes minimal additional storage. The cleanup policy for untagged images keeps costs low.
- API enablement with `disable_on_destroy = false` is important in shared projects. Setting it to `true` would disable the API for the entire project when the module is destroyed, potentially breaking other services.
- IAM best practices for GCP: prefer resource-level IAM bindings (e.g., `google_storage_bucket_iam_member`) over project-level bindings (e.g., `google_project_iam_member`) when possible. This limits the service account's access to only the specific resources it needs.
- The optional log sink enables advanced log management (e.g., export to BigQuery for analysis, long-term GCS archival). For most test deployments, the default Cloud Logging retention (30 days) is sufficient, so the sink is disabled by default.
- Cloud Run Jobs v2 is the current API version. The Terraform `google_cloud_run_v2_job` resource corresponds to this. Do not use the deprecated v1 resources (`google_cloud_run_service`).
- Consider adding a variable `use_existing_vpc` (bool) with `existing_vpc_id` (string) to allow the module to skip VPC creation and use an existing VPC. This is useful when the VPC is managed separately or shared with other services.
- The VPC Access connector has a startup time of 2-5 minutes on first creation. Subsequent Cloud Run Jobs that use the connector start faster. This is a one-time infrastructure cost, not a per-job cost.
- GCP labels have restrictions: keys and values must be lowercase, max 63 characters, and can only contain letters, numbers, hyphens, and underscores. The `locals` block should sanitize labels accordingly.
